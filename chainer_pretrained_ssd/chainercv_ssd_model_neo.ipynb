{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chainerの学習済み物体検出モデルをホスティング\n",
    "\n",
    "## 概要\n",
    "このノートブックでは、Chainerの学習済み物体検出モデルをダウンロードしてホスティングします。物体検出のアルゴリズムはいくつかありますが、ここではSSD (Single Shot Multibox Detector) を利用します。Chainer公式の学習済みモデルは以下からダウンロードすることができます。\n",
    "\n",
    "https://github.com/chainer/chainercv/tree/master/examples/ssd\n",
    "\n",
    "### (注意点)\n",
    "ChainerCVでは、特定のDeep Neural Networks(SSD含む)を構築する関数に、学習済みモデルをロードする機能が提供されているため、本来は*事前の物体検出モデルのダウンロードは不要*です。今回は、学習済みモデルをSageMakerに取り込む方法を一通り体験するために、事前にダウンロードして、別途ロードするという手順を行っています。\n",
    "\n",
    "## 学習済みモデルのダウンロードとS3へのアップロード\n",
    "\n",
    "上記のURLでは、SSD300とSSD512のモデルが提供されており、今回はSSD300を利用します。300や512は入力画像のサイズを表します。一般に512のほうが精度が良いですが、推論に多くの計算を必要とします。\n",
    "\n",
    "SSD300のモデルをダウンロードするために以下を実行します。ダウンロードされたモデルは、このノートブックインスタンスの`/tmp/ssd_model.npz`に保存されます。SageMakerでモデルをホスティングするためには、tar.gz形式にしてS3にアップロードする必要があります。`model.tar.gz`に変換した後、SageMaker Python SDKの`upload_data`を利用してS3にアップロードします。アップロードされる先は、`s3://sagemaker-{リージョン名}-{12桁アカウントID}/notebook/chainercv_ssd/model.tar.gz`になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "# Setup\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# This role retrieves the SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()\n",
    "\n",
    "# Download the model weights.\n",
    "try:\n",
    "    url = 'https://chainercv-models.preferred.jp/ssd300_voc0712_trained_2017_08_08.npz'\n",
    "    urllib.request.urlretrieve (url, '/tmp/ssd_model.npz')\n",
    "\n",
    "# Tar and compress the model.\n",
    "    with tarfile.open('/tmp/model.tar.gz', \"w:gz\") as tar:\n",
    "         tar.add('/tmp/ssd_model.npz', arcname='ssd_model.npz')\n",
    "\n",
    "# Upload the model. The `ChainerModel` will use `uploaded_data` to download this model.\n",
    "\n",
    "    uploaded_model = sagemaker_session.upload_data(path='/tmp/model.tar.gz', \n",
    "                                                   key_prefix='notebook/chainercv_ssd')\n",
    "finally:\n",
    "    os.remove('/tmp/model.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ホスティング用のスクリプトの作成\n",
    "\n",
    "SageMakerでホスティングするためには、モデルの利用方法（どういうモデルを読み込むか、前処理をいれるかなど）を決めるPythonスクリプトが必要になります。Chainerの場合は、シリアライズされたモデルはネットワークの重みだけを含んでいるため、シンボルを定義して、そこに重みの値をロードするという処理が必要になります。\n",
    "\n",
    "同梱されている`chainercv_ssd.py`が、そのためのスクリプトです。`chainercv_ssd.py`には、`model_fn`と`predict_fn`の関数が定義されていることがわかります。以下は、ホスティングのために実装する関数の一覧です。このうち `model_fn` は必ず実装しなければなりません。\n",
    "\n",
    "\n",
    "### ホスティング用関数一覧\n",
    "\n",
    "* **`model_fn(model_dir)`**: この関数は`model_dir`に保存されているモデルをロードする関数です。上述したように、シンボルの定義を行ってからロードします。シンボルの定義にはChainerCVを利用します。\n",
    "\n",
    "* **`input_fn(input_data, content_type)`**: この関数は、推論リクエストを受け付けたときに、推論用のデータ`input_data`に対する前処理を書く関数です。`content_type`を同時に受け取ることができるので、`content_type`に応じて条件分岐を作成し、異なる前処理を実装することができます。\n",
    "  \n",
    "* **`predict_fn(input_data, model)`**: この関数は `input_fn` で前処理されてreturnされた値を`input_data`として受け取り、`model_fn`でロードした`model`で推論するコードを書く関数です。 \n",
    "  \n",
    "* **`output_fn(prediction, accept)`**: この関数は `predict_fn`のreturnした値`prediction`を後処理するための関数です。`accept`に応じて処理を変更することもできます。\n",
    "\n",
    "### 関数の流れ\n",
    "上記では文章で書きましたが、擬似的なコードで示すと、関数の実行順はこのような流れになります。\n",
    "```python\n",
    "# Load a model from file system\n",
    "model = model_fn(model_dir)\n",
    "\n",
    "# Deserialize the Invoke request body into an object we can perform prediction on\n",
    "input_object = input_fn(request_body, request_content_type)\n",
    "\n",
    "# Perform prediction on the deserialized object, with the loaded model\n",
    "prediction = predict_fn(input_object, model)\n",
    "\n",
    "# Serialize the prediction result into the desired response content type\n",
    "output = output_fn(prediction, response_content_type)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルをホスティング\n",
    "\n",
    "S3にモデルをアップロードして、ホスティング用のスクリプトがそろったら、SageMakerにそのモデルを登録します。Chainerの場合は`ChainerModel`を利用します。このとき、アップロードしたモデルと、スクリプトを指定する必要があります。もしモデルを登録したら`deploy`でエンドポイントを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.chainer.model import ChainerModel\n",
    "from sagemaker.utils import sagemaker_timestamp\n",
    "\n",
    "model = ChainerModel(model_data=uploaded_model, role=role, entry_point='chainercv_ssd.py')\n",
    "\n",
    "endpoint_name = 'chainer-ssd-{}'.format(sagemaker_timestamp())\n",
    "\n",
    "predictor = model.deploy(instance_type='ml.m4.xlarge', initial_instance_count=1, endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ホストしたモデルに対して推論リクエストを送信\n",
    "\n",
    "モデルをホストできたら`predictor`を利用して画像を送ります。`predictor.predict(image)`でリクエストを送ることができます。結果が、`predict_fn`で定義したように、bounding box, label, score の順で返ってくることを確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainercv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plot\n",
    "\n",
    "image = chainercv.utils.read_image('images/poodle.jpg', color=True)\n",
    "image = np.ascontiguousarray(image, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox, label, score = predictor.predict(image)\n",
    "print('bounding box: {}\\nlabel: {}\\nscore: {}'.format(bbox, label, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChainerCVを利用すると、簡単に画像の上にbounding box、label、scoreをのせることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from chainercv.visualizations import vis_bbox\n",
    "from chainercv.datasets import voc_bbox_label_names\n",
    "import matplotlib.pyplot as plt\n",
    "vis_bbox(image, bbox, label, score, label_names=voc_bbox_label_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon SageMaker Neoによるモデルのコンパイル\n",
    "\n",
    "**2019.02.28時点では、Neoが物体検出モデルのコンパイルに完全対応しておらず、以降のコードでコンパイルを完了することはできません。**\n",
    "\n",
    "Amazon SageMakerでは、モデルを最適化するためのNeoというサービスを提供しています。モデルの最適化によって、推論速度を向上したり、メモリ消費量を低減したりできるかもしれません。\n",
    "\n",
    "### ONNXモデルへの変換\n",
    "\n",
    "onnx-chainerを利用して、さきほど`/tmp/ssd_model.npz`にダウンロードしたChainerのモデルを、ONNXモデル`/tmp/ssd.onnx`に変換します。その前にSageMakerにインストールされているonnx-chainerを再インストールして新しくします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y onnx-chainer\n",
    "!pip install --no-cache-dir onnx-chainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "インストールが終わると、ChainerCVを利用して、ダウンロードしたモデルを読み込み、`onnx_chainer.export()`を利用して、`/tmp/onnx/model/ssd.onnx`に変換ファイルを保存します。その後、`model.tar.gz`にしてからS3にアップロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx_chainer\n",
    "import chainer\n",
    "import numpy as np\n",
    "from chainercv.links import SSD300\n",
    "from chainercv.datasets import voc_bbox_label_names\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# This role retrieves the SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()\n",
    "\n",
    "path = '/tmp/ssd_model.npz'\n",
    "model = SSD300(n_fg_class=len(voc_bbox_label_names), pretrained_model=path)\n",
    "\n",
    "# Prepare dummy data\n",
    "x = np.zeros((1, 3, 300, 300), dtype=np.float32)\n",
    "\n",
    "# Put Chainer into inference mode\n",
    "chainer.config.train = False\n",
    "\n",
    "# Convert the model to ONNX format\n",
    "import os\n",
    "os.makedirs('/tmp/onnx/model', exist_ok=True)\n",
    "onnx_model = onnx_chainer.export(model, x, filename='/tmp/onnx/model/ssd.onnx')\n",
    "\n",
    "import tarfile\n",
    "archive = tarfile.open('/tmp/onnx/model.tar.gz', mode='w:gz')\n",
    "archive.add('/tmp/onnx/model/', arcname = \"model\")\n",
    "archive.close()\n",
    "\n",
    "uploaded_onnx = sagemaker_session.upload_data(path='/tmp/onnx/model.tar.gz', \n",
    "                                                   key_prefix='notebook/onnx')\n",
    "print(\"ONNX model is uploaded to {}\".format(uploaded_onnx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルのコンパイル\n",
    "\n",
    "モデルをアップロードしたら、Neoを利用してコンパイルします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "onnx_model = Model(model_data = uploaded_onnx,\n",
    "                   image = None,\n",
    "                   sagemaker_session=sagemaker_session,\n",
    "                   role = role)\n",
    "\n",
    "from datetime import datetime\n",
    "compiled_model = onnx_model.compile(target_instance_family='ml_c5', \n",
    "                                     input_shape={'Input_0': [1,3,300,300]},\n",
    "                                     output_path = 's3://'+sagemaker_session.default_bucket() + '/compiled-model/ssd/',\n",
    "                                     role = role,\n",
    "                                     job_name =\"compiled-from-chainer-\" + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"),\n",
    "                                     framework='onnx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_chainer_p36",
   "language": "python",
   "name": "conda_chainer_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific  language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
