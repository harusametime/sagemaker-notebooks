{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 転移学習による画像分類\n",
    "\n",
    "1. [はじめに](#はじめに)\n",
    "2. [データの準備と変換](#データの準備と変換)\n",
    "3. [画像のアップロード](#画像のアップロード)\n",
    "4. [転移学習](#転移学習)\n",
    "5. [推論](#推論)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## はじめに\n",
    "\n",
    "このノートブックでは、画像分類のビルトインアルゴリズムを利用した転移学習を行います。転移学習とは、何らかのデータセットで学習済みのモデルを、異なるデータセットで利用可能にする方法を意味します。転移学習の一般的な方法は、学習したモデルに対して、異なるデータセットで追加学習を行う**Fine-tuning**です。転移学習は、十分な量のないデータセットを補ったり、学習時間を短縮したりするために利用されます。\n",
    "\n",
    "ここでは、以下のような転移学習を行います。\n",
    "- ビルトインアルゴリズムが用意する学習済みモデルを利用\n",
    "- 学習済みモデルに対して[caltech-101データセット](http://www.vision.caltech.edu/Image_Datasets/Caltech101/)でfine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの準備と変換\n",
    "\n",
    "\n",
    "まずは転移学習に利用するcaltech-101データセットをダウンロードします。その名前の通り、100カテゴリ＋その他カテゴリの計101カテゴリからなるデータセットです。Jupyter notebookでは先頭に`!`をつけることでシェルスクリプトを実行できますので`wget`でダウンロードして、`tar`で解凍します。解凍後のフォルダには、以下のようなファイル構造で画像が保存されています。\n",
    "```\n",
    "./101_ObjectCategories/(クラス名)/image_(画像ID).jpg\n",
    "```\n",
    "画像分類のビルトインアルゴリズムが扱うことができるファイルフォーマットは[recordio](https://mxnet.incubator.apache.org/tutorials/basic/record_io.html)と[lst](https://mxnet.incubator.apache.org/how_to/recordio.html?highlight=im2rec)です。今回はrecordio形式を利用しますので、変換のためのツール`im2rec.py`をMXNetの[githubレポジトリ](https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py)から`wget`でダウンロードします。`im2rec.py`の利用方法は以下の通りです。なおmxnetを利用しますので、右上のカーネルの表示が`conda_mxnet_p36`になっていることを確認してください。もし異なるようでしたら、丈夫のメニューKernelからChane Kernelで`conda_mxnet_p36`を選びます。\n",
    "\n",
    "1. lstファイルを作成します。lstファイルは、`(画像のindex) (ラベルID) (画像パス)`のタブ区切りの情報です。この際に、クラスのインデックスとクラス名が出力されるのでファイル`class_index`に保存しましょう。\n",
    "```\n",
    "!python im2rec.py --list --recursive --train-ratio (学習データの割合) --test-ratio (テストデータの割合) (recのファイル名) (データセットのルートディレクトリ) > (クラスのインデックス情報を保存するファイル名)\n",
    "```\n",
    "\n",
    "2. lstファイルにもとづいてrecファイルを作成します。\n",
    "```\n",
    "!python im2rec.py --num-thread (並列処理数) caltech101 ./101_ObjectCategories\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!wget http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz\n",
    "!tar xvzf 101_ObjectCategories.tar.gz\n",
    "!wget https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py\n",
    "!python im2rec.py --list --recursive --train-ratio 0.80  --test-ratio 0.10 caltech101 ./101_ObjectCategories > class_index\n",
    "!python im2rec.py --num-thread 16 --resize 200 caltech101  ./101_ObjectCategories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像のアップロード\n",
    "\n",
    "\n",
    "recファイルをS3にアップロードします。アップロード先は、バケット名がdefault_backet()によって自動設定されるsagemaker-{region}-{AWS account ID}で、prefixが`notebook/transfer/caltech`となります。バケット名も自由に設定できますが、世界中で唯一の名前となるような設定が必要です。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# Upload files to S3\n",
    "prefix = 'notebook/transfer/caltech'\n",
    "train_input = sess.upload_data(\n",
    "        path='caltech101_train.rec', \n",
    "        key_prefix=prefix)\n",
    "valid_input = sess.upload_data(\n",
    "        path='caltech101_val.rec', \n",
    "        key_prefix=prefix)\n",
    "test_input = sess.upload_data(\n",
    "        path='caltech101_test.rec', \n",
    "        key_prefix=prefix)\n",
    "\n",
    "\n",
    "# Show S3 path \n",
    "print(\"Training data is uploaded to\", train_input)\n",
    "print(\"Validation data is uploaded to \", valid_input)\n",
    "print(\"Test data is uploaded to \", valid_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 転移学習\n",
    "\n",
    "転移学習を以下の手順で行うことができます。\n",
    "- ビルトインアルゴリズムのうち*image classification*を実行するコンテナイメージを指定します。\n",
    "- コンテナイメージにもとづいて*estimator*を呼び出します。この際、学習インスタンス数やタイプ、モデルの出力パスを指定します。*image classification*では、GPUインスタンスのみで学習可能です。\n",
    "- 転移学習のためのハイパーパラメータを指定します。転移学習では`use_pretrained_model=1`を指定する必要があります。ハンズオンのため最小構成（レイヤ数18、デフォルト152)で行います。\n",
    "- S3のデータに対して`application/x-recordio`形式であることを明示的に指定して、`fit`を実行すると学習が始まります。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "training_image = get_image_uri(boto3.Session().region_name, 'image-classification')\n",
    "\n",
    "img_transfer = sagemaker.estimator.Estimator(training_image,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.p2.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                   sagemaker_session=sess)\n",
    "img_transfer.set_hyperparameters(\n",
    "                        num_classes=101,\n",
    "                        num_training_samples=7315,\n",
    "                        use_pretrained_model=1,\n",
    "                        num_layers = 18,\n",
    "                        epochs=3,\n",
    "                        learning_rate=0.01,\n",
    "                        mini_batch_size=128,\n",
    "                        image_shape='3,200,200',\n",
    "                        top_k=2)\n",
    "\n",
    "\n",
    "from sagemaker.session import s3_input\n",
    "train_rec = s3_input(s3_data=train_input, content_type='application/x-recordio')\n",
    "valid_rec = s3_input(s3_data=valid_input, content_type='application/x-recordio')\n",
    "img_transfer.fit({'train': train_rec, 'validation': valid_rec})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論\n",
    "\n",
    "### エンドポイントの作成\n",
    "学習が終わると`deploy`を呼び出すことでエンドポイントを作成することできます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_predictor = img_transfer.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデータに対する推論\n",
    "\n",
    "recordio形式のファイルを作成する際に、学習に利用していないテストデータを残しています。テストデータの一覧`caltech101_test.lst`から画像をランダムに1つ選んで推論してみましょう。デフォルトではバイナリ形式で結果を出力するので、解析しやすいようjson系形式で出力するようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import  json_deserializer\n",
    "img_predictor.content_type = \"application/x-image\"\n",
    "img_predictor.deserializer = json_deserializer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "test_list = pd.read_table('caltech101_test.lst', header=None)\n",
    "rand_index =  np.random.choice(test_list.index, 1)\n",
    "file_path = './101_ObjectCategories/'+test_list.iat[int(rand_index), 2]\n",
    "\n",
    "class_index =pd.read_csv('class_index', sep=' ',header=None, index_col=[1])\n",
    "\n",
    "%matplotlib inline\n",
    "from skimage import io, transform\n",
    "from matplotlib import pyplot as plt\n",
    "io.imshow(file_path)\n",
    "plt.show()\n",
    "with open(file_path, 'rb') as f:\n",
    "    response = img_predictor.predict(f.read())\n",
    "    np_resp = np.array(response)\n",
    "    rank = np_resp.argsort()[::-1] # Reversing makes the array descending.\n",
    "    \n",
    "    # Show top 5\n",
    "    for i in range(5):\n",
    "        print(\"Class: {} (Confidence: {:.3f})\".format(class_index.loc[rank[i]].values[0], np_resp[rank[i]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### エンドポイントの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
